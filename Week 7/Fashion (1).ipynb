{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZewjElECYhA"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f3gLYwVCYhC"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzce6QCiCYhC"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmZ_dk43CYhD",
        "outputId": "69847dd7-f54f-4d6c-bbae-8c7b0f7499ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "# X_train = ...\n",
        "# y_train = ...\n",
        "# X_test = ...\n",
        "# y_test = ...\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojYf1SVbCYhE"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQIF_WioCYhE"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "hZTLa7nlCYhE",
        "outputId": "8940e6bb-b132-45cc-8ed3-8808a2a323d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap = \"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox27hIzQCYhF"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XET3HDoJCYhF"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT3hfUMNCYhF"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIj8-nuJCYhG",
        "outputId": "d71e83bb-ccf0-4696-b4e5-46bf7c02c1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes = 10)\n",
        "y_test_cat = to_categorical(y_test, num_classes = 10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "print(np.shape(X_train_norm))\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "print(np.shape(X_test_norm))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], np.prod(X_train_norm.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSTE9QNsCYhG"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65MU1sR0CYhG",
        "outputId": "2af5aa66-54cb-4c9a-ede6-1693b9d8ca43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8070 (31.52 KB)\n",
            "Trainable params: 8070 (31.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10, input_dim = input_dim, activation = \"sigmoid\"))\n",
        "    model.add(Dense(10, activation = \"sigmoid\"))\n",
        "\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s89DzsLCYhG"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_7obLSaCYhG",
        "outputId": "1bc3dbe4-72b6-46c7-f938-aab2d833a3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 6s 10ms/step - loss: 1.9405 - accuracy: 0.4628\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.3190 - accuracy: 0.6742\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.0132 - accuracy: 0.7141\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8491 - accuracy: 0.7503\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.7267 - accuracy: 0.8000\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6275 - accuracy: 0.8249\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5574 - accuracy: 0.8353\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5125 - accuracy: 0.8403\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.8463\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.8505\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4452 - accuracy: 0.8527\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4340 - accuracy: 0.8544\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4234 - accuracy: 0.8575\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4150 - accuracy: 0.8593\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4086 - accuracy: 0.8604\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4009 - accuracy: 0.8625\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3962 - accuracy: 0.8630\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3915 - accuracy: 0.8645\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3867 - accuracy: 0.8661\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.8668\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3784 - accuracy: 0.8678\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3744 - accuracy: 0.8694\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3719 - accuracy: 0.8704\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3684 - accuracy: 0.8712\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3659 - accuracy: 0.8719\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3637 - accuracy: 0.8731\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3609 - accuracy: 0.8741\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3587 - accuracy: 0.8735\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3559 - accuracy: 0.8744\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3546 - accuracy: 0.8754\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3518 - accuracy: 0.8770\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3502 - accuracy: 0.8770\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.8768\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8774\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3441 - accuracy: 0.8795\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3433 - accuracy: 0.8791\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3414 - accuracy: 0.8807\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3403 - accuracy: 0.8797\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3399 - accuracy: 0.8809\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8819\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8825\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8825\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8818\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3332 - accuracy: 0.8828\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3320 - accuracy: 0.8832\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8837\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3297 - accuracy: 0.8838\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8832\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8845\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3272 - accuracy: 0.8847\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3263 - accuracy: 0.8851\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8845\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8846\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3231 - accuracy: 0.8863\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.8865\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3216 - accuracy: 0.8868\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8865\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3207 - accuracy: 0.8862\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3189 - accuracy: 0.8870\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3189 - accuracy: 0.8877\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.8879\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.8878\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3168 - accuracy: 0.8881\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3160 - accuracy: 0.8886\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.8873\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3142 - accuracy: 0.8892\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3144 - accuracy: 0.8891\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3127 - accuracy: 0.8897\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3128 - accuracy: 0.8899\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3125 - accuracy: 0.8901\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3121 - accuracy: 0.8902\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3116 - accuracy: 0.8900\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3105 - accuracy: 0.8900\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3101 - accuracy: 0.8903\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3096 - accuracy: 0.8909\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.8908\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3079 - accuracy: 0.8910\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8908\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3068 - accuracy: 0.8922\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3061 - accuracy: 0.8907\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3057 - accuracy: 0.8920\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.8907\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3041 - accuracy: 0.8921\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.8918\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.8918\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3039 - accuracy: 0.8924\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3037 - accuracy: 0.8918\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3022 - accuracy: 0.8924\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8916\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.8927\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3018 - accuracy: 0.8921\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3010 - accuracy: 0.8932\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2997 - accuracy: 0.8934\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.8934\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3003 - accuracy: 0.8933\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.8935\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2974 - accuracy: 0.8946\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2977 - accuracy: 0.8939\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.8929\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2972 - accuracy: 0.8940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bd1d1575ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMmKat4wCYhH"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_FouqLICYhH",
        "outputId": "250dd4fe-a05a-4490-e99e-53f4cf3dc34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.8913999795913696\n",
            "accuracy on test with NN: 0.8546000123023987\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uV3C3nZCYhH"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfTvsNHDCYhH"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t3GGYoACYhH"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "S8ozL9RVCYhH"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components = 0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvF5bdDtCYhH",
        "outputId": "72dc3ad1-ed26-473a-d9c4-97d1971782ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on train 0.8613\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on train', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq8fLJBsCYhI"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMQhl-H3CYhI"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}